Apache Kafka
---
### Broker
- Broker
  - 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션 
  - 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다
  - 카프카 브로커 서버 1대로도 기본 기능이 실행되지만, 데이터를 안전하게
    보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영
  - 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게
    분산 저장하고 복제하는 역할을 수행
  - 카프카는 메모리나 데이터베이스에 저장하지 않으며, 따로 캐시
    메모리를 구현하여 사용하지 않는다.
    - 파일 시스템에 저장하지만, 카프카는 페이지 캐시(page cache)를 사용하여 디스크의 입출력 속도를 높
      여서 성능 저하의 문제를 해결
    - 페이지 캐시: OS에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모
      리 영역. 한번 읽은 파일의 내용은 메모리의 페이지 캐시 영역에 저장 시킨다. 추후 동일한 파일의 접근이 일어나면 디스크에서 읽지 않고,
      메모리에서 직접 읽는 방식
- Replication: follower는 leader의 오프셋을 확인하여 현재 자신의 오프셋과 차이나는 경우, 데이터를 가져와 파티션에 저장
    - kafka는 데이터를 안전하게 저장하기 위해 복제(replication) 기능을 제공하여 장애 허용 시스템(fault tolerant system)으로 동작
    - 복제는 파티션 단위로 이뤄지며 토픽 생성 시 replication factor를 설정, 설정하지 않으면 브로커에 설정된 옵션값을 적용(최소 1(복제없음), 최대 브로커의 개수)
    - 복제된 파티션은 leader와 follower로 나뉘며, leader는 프로듀서, 컨슈머와 직접 통신하는 대상이 되고, follower는 leader의 데이터를 복제하는 역할을 수행
    - 장점 
      - 고가용성 확보: 장애 발생 시 leader가 다운되더라도, 다른 follower가 leader로 승격되어 장애를 복구할 수 있다.
      - 데이터의 유실이 일어나면 안되는 경우(금융정보 등) 복제 개수를 3으로 설정하여 안정적 운영
    - 단점
      - 복제된 파티션이 많아질수록 데이터 저장 공간이 늘어나고, 복제 과정에서 성능 저하가 발생할 수 있다.
      - 데이터 처리 속도가 중요하고, 일부 유실되어도 무관한 경우, 복제 개수를 1~2로 설정하여 성능을 높일 수 있다.
- 데이터의 삭제
    - 카프카는 컨슈머가 데이터를 가져가더라도 토픽의 데이터가 삭제되지 않으며, 오직 브로커만이 데이터를 삭제할 수 있음
    - 로그 세그먼트(log segment)
      - 카프카는 파일단위로 데이터를 저장 및 삭제, 이 때의 단위를 로그 세그먼트라고 함
      - 로그 세그먼트에는 다수의 데이터가 존재하며, 특정 데이터를 선별해서 삭제는 불가능
      - 세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려 있으며, 특정 사이즈나 시간에 도달하면 새로운 세그먼트로 교체
        - log.segment.bytes: 세그먼트의 최대 크기(기본 1GB)
        - log.segment.ms: 세그먼트의 최대 시간
        - log.retention.bytes: 세그먼트의 최대 보관 크기(기본 -1, 무제한)
          - 저장된 데이터의 크기가 이 값을 초과하면 가장 오래된 세그먼트부터 삭제
        - log.retention.ms: 세그먼트의 보관 주기(default 7일)
        - log.retention.check.interval.ms: 설정된 값의 주기에 따라 닫힌 세그먼트 파일을 체크(default 5분)
        - 너무 작은 값(시간, 용량)을 설정하면, 세그먼트가 자주 닫히고 열리면서 성능 저하가 발생할 수 있음
        - 데이터를 삭제하지 않고, 메세지키를 기준으로 오래된 데이터를 압축하는 전략도 고려 가능
- Consumer offset
  - consumer group은 토픽의 특정 파티션으로부터 데이터를 가져가 처리한 뒤, 
    해당 파티션의 오프셋을 커밋하여 다음에 가져갈 위치를 저장
  - 커밋한 오프셋은 브로커의 내부 토픽인 __consumer_offsets에 저장
- 컨트롤러
    - 다른 브로커의 상태를 체크하고, 브로커가 클러스터에서 빠지는 경우 해당 브로커의 리더 파티션을 재분배하는 역할을 수행
    - 클러스터 내의 브로커 중 한대가 컨트롤러 역할 수행
    - 지속적인 데이터 처리를 위해 브로커의 상태가 비정상이라면 빠르게 빼내는 것이 중요
    - 컨트롤러에 장애 발생 시 클러스터 내의 다른 브로커 중 하나가 컨트롤러 역할을 수행
- 코디네이터
  - 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할
  - 클러스터 내의 브로커 중 하나가 코디네이터 역할을 수행
  - rebalance
    - 컨슈머 그룹의 상태가 변경되거나, 컨슈머가 추가되거나 제거되는 경우, 코디네이터는 컨슈머 그룹의 파티션을 재분배하는 작업을 수행
---
### Topic, Partition
- Topic
  - 카프카에서 데이터 구분하는 단위
  - 토픽은 1개 이상의 파티션을 소유하며, 프로듀서가 보낸 데이터(record)는 파티션에 저장
  - 토픽명의 제약조건
    - 생성 불가: "", ".", ".." 
    - 294자 미만
    - 영문, 숫자, 밑줄(_), 하이픈(-), 마침표(.)만 허용
      - 카프카 내부 로직으로 인해 마침표와 언더바가 동시에 들어가면 이슈가 발생할 수 있음
      - 이미 생성된 토픽명에서 마침표를 언더바로 변경 또는 언더바를 마침표로 변경한 이름은 생성 불가
        - to.pic이 있는 경우 to_pic 생성 불가능
    - 카프카 내부 토픽인 __consumer_offsets, __transaction_state 은 생성 불가
  - 토픽 이름 작명법
    - 토픽 작명 템플릿과 예시
      - <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>
      - prd.marketing-teams.marketing-platform.json
      - <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>
      - commerce.payment.prd.notification

- Partition
  - 카프카 병렬처리의 핵심
  - 컨슈머 그룹 내의 컨슈머들이 레코드를 병렬 처리할 수 있도록 매칭
  - 파티션과 컨슈머의 개수를 동시에 늘려 throughput 향상 가능
  - 큐와 유사하지만, 가져간 데이터가 삭제되지 않고, 컨슈머 그룹별로 관리되어 여러 컨슈머 그룹이 토픽의 데이터를 여러번 가져갈 수 있음
- Record
  - 카프카에서 데이터를 표현하는 단위
  - 레코드는 메시지키(key), 메시지값(value), 타임스탬프(timestamp), 오프셋(offset)으로 구성
    - 메시지키
      - 메시지 값을 순서대로 처리하거나, 메시지 값의 종류를 나타내기 위해 사용
      - 메시지 키의 해시값을 토대로 파티션을 결정(파티션의 개수가 변경되면, 키와 파티션의 매핑이 변경될 수 있음)
      - 메시지 키를 설정하지 않으면 Null로 설정되며, 프로듀서의 설정 파티셔너에 따라 분배되어 적재
    - 메시지값
      - 처리해야할 데이터
      - 메시지 키와 값은 직렬화 되어 브로커로 전송 -> 컨슈머가 이용 시에는 반드시 동일한 역직렬화를 수행해야 함
    - 타임스탬프
      - 브로커 기준 유닉스 타임스탬프 설정
    - 오프셋
      - 직접 지정이 불가능, 브로커가 이전 레코드의 오프셋 + 1로 자동 할당
      - 컨슈머가 데이터를 가져갈 때 사용
  - 브로커에 적재된 레코드는 수정할 수 없으며, log.retention.ms, log.retention.bytes 설정에 따라 삭제됨
---
### Producer
  - 카프카에 데이터를 보내는 주체
  - 카프가에 필요한 데이터를 선언하고 브로커에 특정 토픽의 데이터를 전송
  - 리더 파티션을 가지고 있는 브로커와 직접 통신
  - 카프카 클라이언트를 라이브러리러 추가하여 프로듀서 구현
  - 자바에서 선언 가능한 모든 형태를 직렬화 하여 브로커로 전송 가능
  - 데이터 전송 시, 내부적으로 파티셔너, 배치 생성 단계를 거침
    - 파티션 번호, 타임스탬프, 메시지키를 지정 가능 
    - KafkaProducer 인스턴스에서 send() 메서드 호출 -> 파티셔너에서 토픽의 어느 파티션으로 ProducerRecord를 전송할지 결 -> 구분된 레코드는 accumulator에 데이터 버퍼로 쌓아놓고 배치로 묶어 전송
    - 메시지키값이 없는 경우, 각 파티션에 최대한 동일하게 분배하는 파티셔너를 사용
      - UniformStickyPartitioner(2.5버전 이상 default, RoundRobin의 단점 개선)
      - RoundRobinPartitioner
  - 압축옵션을 지정하여 데이터 전송 시 압축하여 전송할 수 있다.
    - 압축 알고리즘: gzip, snappy, lz4, zstd 지원
    - 지정하지 않으면 압축하지 않음
    - 압축 시 네트워크 처리량에서 이득을 보지만, 압축으로 인해 CPU, 메모리 사용량이 증가할 수 있음
  - 주요 옵션
    - 필수
      - bootstrap.servers: 데이터를 전송할 클러스터에 속한 브로커의 호스트:포트를 1개 이상 작성 -> 2개 이상 입력시, 
        브로커 중 하나가 다운되더라도 다른 브로커에 연결 가능
      - key.serializer: 메시지키를 직렬화할 클래스
      - value.serializer: 메시지값을 직렬화할 클래스
    - 선택
      - acks: 프로듀서가 데이터를 전송한 후, 브로커로 전송 성공 여부를 확인하는 옵션
        - 0: 응답을 기다리지 않음(성능은 좋지만, 데이터 유실 가능성 있음)
        - 1(default): 리더 파티션에 데이터가 저장되면 성공(리더 파티션이 다운되면 데이터 유실 가능성 있음)
        - -1(all): min.insync.replicas 만큼에 해당하는 파티션에 데이터가 저장되면 성공(데이터 유실 가능성 없음)
      - buffer.memory: 배치로 전송할 데이터를 모으기 위한 버퍼 메모리의 크기(기본 32MB)
      - retries: 전송 실패 시 재시도 횟수(기본 2147483647)
      - batch.size: 배치로 묶어 전송할 레코드의 최대 용량(기본 16384)
      - linger.ms: 배치로 묶어 전송할 때, 대기 시간(기본 0)
      - partitioner.class: 파티션을 결정하는 클래스(파티셔너)
      - enable.idempotence: 멱등성 프로듀서로 동작 여부(기본 false)
        - 데이터의 중복 적재없이 메세지를 정확히 한 번만 적재하도록 보장
      - transactional.id: 레코드 전송 시 트랜잭션 단위로 묶을지 여부
---
### Consumer
- 카프카에서 브로커로부터 데이터를 가져가는 주체
- 컨슈머 그룹
  - 컨슈머 그룹은 하나 이상의 컨슈머로 구성되어 있으며, 토픽의 파티션을 병렬로 처리
  - 컨슈머 그룹은 토픽의 파티션을 컨슈머와 매칭하여 병렬 처리
  - 컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징이 있어, 서로 영향을 미치지 않고 데이터 처리가 가능
  - 컨슈머 그룹 내에서, 1개의 컨슈머는 여러 개의 파티션과 매칭될 수 있지만, 1개의 파티션은 1개의 컨슈머와만 매칭될 수 있다. 따라서, 컨슈머 그룹 내의 컨슈머의 개수는 토픽의 파티션 개수보다 작거나 같아야 한다.
  - rebalancing
    - 컨슈머 그룹의 상태가 변경되거나, 컨슈머가 추가되거나 제거되는 경우, 코디네이터는 컨슈머 그룹의 파티션을 재분배하는 작업을 수행
  - 주요 옵션
    - 필수
      - bootstrap.servers: 데이터를 가져올 클러스터에 속한 브로커의 호스트:포트를 1개 이상 작성 -> 2개 이상 입력시, 
        브로커 중 하나가 다운되더라도 다른 브로커에 연결 가능
      - key.serializer: 메시지키를 역직렬화할 클래스
      - value.serializer: 메시지값을 역직렬화할 클래스
    - 선택 
      - group.id: 컨슈머 그룹의 ID
      - enable.auto.commit: 백그라운드로 주기적 오프셋 커밋
      - session.timeout.ms: 컨슈머-브로커 사이 세션 타임아웃 시간
      - heartbeat.interval.ms: 컨슈머가 브로커에 하트비트 메시지(KafkaConsumer.poll() 메서드)를 보내는 주기
        - 세션 타임아웃 시간보다 짧게 설정해야 함(일반적으로 session.timeout.ms의 1/3 정도)
        - 세션 타임아웃 시간보다 길게 설정하면, 컨슈머가 브로커와 연결이 끊어진 것으로 간주되어 컨슈머 그룹에서 제외될 수 있음
      - max.poll.records: 한 번의 poll() 메서드 호출로 가져올 수 있는 레코드의 최대 개수

---
### 카프카 설치 및 사용
- 카프카 설치
  - 웹사이트에서 다운로드 또는 brew 활용 설치
  ```shell
    brew install kafka
  ```
  - 카프카 실행
    - 3.3 버전부터는 zookeeper 없이 kRaft로 컨트롤러를 관리하여 실행 가능
    - 4.0 버전부터는 zookeeper가 제거되고 kRaft 모드가 기본으로 설정되어 있음
    - 설치 경로로 접속하여 kafka-server-start.sh 스크립트로 실행
    - 별도 설정 없이 실행하는 경우, controller 브로커는 9093 포트로 실행, 브로커는 9092 포트로 실행
    ```shell
      bin/kafka-server-start.sh config/server.properties
    ```
  - 토픽 생성
    - quickstart-events라는 이름의 토픽을 생성
    ```shell
    bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
    ```
  - 토픽 조회
    - 생성된 토픽의 정보를 조회
      ```shell
      bin/kafka-topics.sh --bootstrap-server=localhost:9092 --list
      ```
